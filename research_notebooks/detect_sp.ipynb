{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smb/Documents/code/detect_simpsons_paradox_dev/env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/smb/Documents/code/detect_simpsons_paradox_dev/env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install our package, then import it.\n",
    "\n",
    "_this is here as an example, and for development, eventually this install step shouldn't be in the notebooks, only in the main readme_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/smb/Documents/code/detect_simpsons_paradox_dev\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in ./env/lib/python3.6/site-packages (from detect-simpsons-paradox==0.2) (2.2.2)\n",
      "Requirement already satisfied, skipping upgrade: Numpy in ./env/lib/python3.6/site-packages (from detect-simpsons-paradox==0.2) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: Scipy in ./env/lib/python3.6/site-packages (from detect-simpsons-paradox==0.2) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: seaborn in ./env/lib/python3.6/site-packages (from detect-simpsons-paradox==0.2) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: pandas in ./env/lib/python3.6/site-packages (from detect-simpsons-paradox==0.2) (0.23.4)\n",
      "Requirement already satisfied, skipping upgrade: fairsim in ./env/lib/python3.6/site-packages (from detect-simpsons-paradox==0.2) (0.1)\n",
      "Requirement already satisfied, skipping upgrade: flask in ./env/lib/python3.6/site-packages (from detect-simpsons-paradox==0.2) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in ./env/lib/python3.6/site-packages (from matplotlib->detect-simpsons-paradox==0.2) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in ./env/lib/python3.6/site-packages (from matplotlib->detect-simpsons-paradox==0.2) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in ./env/lib/python3.6/site-packages (from matplotlib->detect-simpsons-paradox==0.2) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in ./env/lib/python3.6/site-packages (from matplotlib->detect-simpsons-paradox==0.2) (2018.5)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in ./env/lib/python3.6/site-packages (from matplotlib->detect-simpsons-paradox==0.2) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in ./env/lib/python3.6/site-packages (from matplotlib->detect-simpsons-paradox==0.2) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in ./env/lib/python3.6/site-packages (from flask->detect-simpsons-paradox==0.2) (6.7)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.14 in ./env/lib/python3.6/site-packages (from flask->detect-simpsons-paradox==0.2) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in ./env/lib/python3.6/site-packages (from flask->detect-simpsons-paradox==0.2) (0.24)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.10 in ./env/lib/python3.6/site-packages (from flask->detect-simpsons-paradox==0.2) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in ./env/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->detect-simpsons-paradox==0.2) (40.0.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in ./env/lib/python3.6/site-packages (from Jinja2>=2.10->flask->detect-simpsons-paradox==0.2) (1.0)\n",
      "Building wheels for collected packages: detect-simpsons-paradox\n",
      "  Running setup.py bdist_wheel for detect-simpsons-paradox: started\n",
      "  Running setup.py bdist_wheel for detect-simpsons-paradox: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-lqwqqets/wheels/6f/33/e5/2e2b04658a9facaec056625f497ea9c4a21448cb987ce85d62\n",
      "Successfully built detect-simpsons-paradox\n",
      "Installing collected packages: detect-simpsons-paradox\n",
      "  Found existing installation: detect-simpsons-paradox 0.2\n",
      "    Uninstalling detect-simpsons-paradox-0.2:\n",
      "      Successfully uninstalled detect-simpsons-paradox-0.2\n",
      "Successfully installed detect-simpsons-paradox-0.2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd .. \n",
    "pip install . --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detect_simpsons_paradox as dsp\n",
    "import fairsim as sp_dat \n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fairsim' has no attribute 'simple_regression_sp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-15ce7390c903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlatent_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp_dat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_regression_sp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#mixed_regression_sp(N,mu,cov,[.7,.3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'fairsim' has no attribute 'simple_regression_sp'"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "# sample data from 2 clusters\n",
    "mu = np.asarray([[1,1],[5,5]])\n",
    "cov = [[.6,-1],[0,.6]]\n",
    "\n",
    "latent_df = sp_dat.simple_regression_sp(N,mu,cov)\n",
    "#mixed_regression_sp(N,mu,cov,[.7,.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract contiunous variables and categorical variables\n",
    "\n",
    "Categorical attributes' types contain 'object' and 'int64'.\n",
    "Continuous attributes' type contains float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the continous attributes and categorical attributes from datasets\n",
    "groupbyAttrs = latent_df.select_dtypes(include=['object','int64'])\n",
    "continuousAttrs = latent_df.select_dtypes(include=['float64'])\n",
    "continuousAttrs_labels = list(continuousAttrs)\n",
    "groupbyAttrs_labels = list(groupbyAttrs)\n",
    "print(continuousAttrs_labels)\n",
    "print(groupbyAttrs_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute correaltion matrix for all of the data, then extract the upper triangle of the matrix.\n",
    "Generate the correaltion dataframe by correlation values and their discrete variables' index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corr = latent_df[continuousAttrs_labels].corr()\n",
    "\n",
    "all_corr_df = dsp.upper_triangle_df(all_corr)\n",
    "all_corr_element = all_corr_df['value'].values\n",
    "print(all_corr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the signs of each correlation in the subgroup to the correlation for all\n",
    "After comparing, the reverse result will be stored in the result_df dataframe for further usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an empty dataframe for result\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for groupbyAttr in groupbyAttrs_labels:\n",
    "    grouped_df_corr = latent_df.groupby(groupbyAttr)[continuousAttrs_labels].corr()\n",
    "    groupby_value = grouped_df_corr.index.get_level_values(groupbyAttr).unique()\n",
    "    \n",
    "    # get subgroup correlation\n",
    "    for subgroup in groupby_value:\n",
    "        subgroup_corr = grouped_df_corr.loc[subgroup]\n",
    "        \n",
    "        # Extract subgroup \n",
    "        subgroup_corr_elements = dsp.upper_triangle_element(subgroup_corr)\n",
    "        \n",
    "        # Compare the signs of each element in subgroup to the correlation for all of the data\n",
    "        # Get the index for reverse element\n",
    "        index_list = [i for i, (a,b) in enumerate(zip(all_corr_element, subgroup_corr_elements)) \n",
    "                      if dsp.isReverse(a, b)]\n",
    "        \n",
    "        # Get reverse elements' correlation values\n",
    "        reverse_list = [j for i, j in zip(all_corr_element, subgroup_corr_elements) \n",
    "                        if dsp.isReverse(i, j)]\n",
    "        \n",
    "        if reverse_list:\n",
    "            # Retrieve attribute information from all_corr_df\n",
    "            all_corr_info = [all_corr_df.loc[i].values for i in index_list]\n",
    "            temp_df = pd.DataFrame(data=all_corr_info,columns=['allCorr','attr1','attr2'])\n",
    "            \n",
    "            # Convert index from float to int\n",
    "            temp_df.attr1 = temp_df.attr1.astype(int)\n",
    "            temp_df.attr2 = temp_df.attr2.astype(int)\n",
    "            \n",
    "            temp_df[\"reverseCorr\"] = reverse_list\n",
    "            len_list = len(reverse_list)\n",
    "            # Store group attributes' information\n",
    "            temp_df['groupbyAttr'] = [groupbyAttr for i in range(len_list)]\n",
    "            temp_df['subgroup'] = [subgroup for i in range(len_list)]\n",
    "            result_df = result_df.append(temp_df, ignore_index=True)\n",
    "        \n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Visualization (Hard code modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by color\n",
    "grouped_df_color = latent_df.groupby('color')['x1','x2','x3'].corr()\n",
    "blue=grouped_df_color.loc['b']\n",
    "red=grouped_df_color.loc['r']\n",
    "\n",
    "# group by char\n",
    "grouped_df_char = latent_df.groupby('char')['x1','x2','x3'].corr()\n",
    "char_o=grouped_df_char.loc['o']\n",
    "char_x=grouped_df_char.loc['x']\n",
    "\n",
    "# create a 0 matrix for the irrelvant cells\n",
    "s = (len(blue),len(blue))\n",
    "zero = np.zeros(s)\n",
    "\n",
    "# manipulate the subgroup matrix first after corr() method\n",
    "color_group=np.vstack([np.hstack([blue, zero]), np.hstack([zero, red])])\n",
    "\n",
    "# create a 0 matrix for the irrelvant cells\n",
    "s = (len(all_corr),len(color_group))\n",
    "zero1 = np.zeros(s)\n",
    "\n",
    "# combine the correlation matrix of all of the data with subgroup by color\n",
    "all_combined=np.vstack([np.hstack([all_corr, zero1]), np.hstack([zero1.transpose(), color_group])])\n",
    "\n",
    "# Combine char group\n",
    "s = (len(char_o),len(char_x))\n",
    "zero = np.zeros(s)\n",
    "char_group=np.vstack([np.hstack([char_o, zero]), np.hstack([zero, char_x])])\n",
    "s = (len(all_combined),len(char_group))\n",
    "zero1 = np.zeros(s)\n",
    "all_combined=np.vstack([np.hstack([all_combined, zero1]), np.hstack([zero1.transpose(), char_group])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ why a heat map?__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a heatmap for correlation matrix\n",
    "cmap = mcolors.LinearSegmentedColormap.from_list('mycmap', ['red', 'white', 'blue'])\n",
    "norm = plt.Normalize(-1,1)\n",
    "\n",
    "labels =  ['x1','x2','x3','x1_b','x2_b','x3_b','x1_r','x2_r','x3_r','x1_o','x2_o','x3_o','x1_x','x2_x','x3_x']\n",
    "plt.figure(figsize=(11, 9))\n",
    "\n",
    "ax = sns.heatmap(all_combined, cmap=cmap, annot=True, fmt=\".2f\", xticklabels=labels, yticklabels=labels, linewidths=.5, norm=norm, center=0)\n",
    "\n",
    "# Offset 0.00\n",
    "for t in ax.texts: \n",
    "    if t.get_text() == '0.00':\n",
    "        t.set_text(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
